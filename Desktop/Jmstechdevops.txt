connect mobaxterm for windows version:
--------------------------------------
ssh -i <location of PEM> <username>@<ip>
ssh -i jmspem.pem ec2-user@

Apache server log github:
-------------------------
https://gist.github.com/rm-hull/bd60aed44024e9986e3c

abc 5
abcd 6
abcdef 8
dcd 7
affd 9

5. Devops_Linux_realtime_log_trobuleshoot:
==========================================
[ec2-user@ip-172-31-10-164 ~]$ history
    1  clear
    2  ls -ltr
    3  pwd
    4  du
    5  free
    6  top
    7  df
    8  netstat
    9  telnet
   10  yum install telnet
   11  sudo yum install telnet
   12  telnet
   13  w
   14  fdisk
   15  wc
   16  uptime
   17  man
   19  iostat
   20  vmstat
   21  pwd
   22  sudo -i
   23  mkdir devops
   24  ls
   25  ls -l
   26  man ls
   27  whatis cp
   28  whatis ls
   29  whatis netsata
   30  whatis netstat
   31  cd devops/
   32  ls
   33  ls -ltr
   34  mkdir course
   35  cd cor
   36  cd course/
   37  pwd
   38  mkdir -p madhucourse/linux
   39  ls -ltr
   40  cd madhucourse/
   41  ls
   42  cd ..
   43  cd madhucourse/linux/
   44  cd
   45  cd -
   46  cd ../..
   47  pwd
   48  cd
   49  cd devops/
   50  ls
   51  touch sample.txt
   52  ll
   53  vi example.txt
   54  ll
   55  vi example.txt
   56  ls -li
   57  echo --> test1.txt
   58  ls -ltr
   59  echo "this is devops course"
   60  echo $USER
   61  env
   62  env | grep -i user\
   63  env | grep -i user
   64  env | grep -i USER
   65  env | grep USER
   66  vi sample.txt
   67  cat sample.txt
   68  cat sample.txt | grep devops
   69  cat sample.txt | grep -i devops
   70  ifconfig
   71  hostname
   72  vi hostname
   73  ifconfig | grep inet
   74  ifconfig | grep -w inet
   75  ifconfig | grep -w inet | awk 2
   76  ifconfig | grep -w inet | awk '{print $1}'
   77  ifconfig | grep -w inet | awk '{print $2}'
   78  ifconfig | grep -w inet | awk '{print $3}'
   79  ifconfig | grep -w inet | awk '{print $2}'
   80  ifconfig | grep -w inet | awk '{print $2}' |wc
   81  ifconfig | grep -w inet | awk '{print $2}' | wc -l
   82  ifconfig | grep -w inet | awk '{print $2}' | wc -c
   83  ifconfig | grep -w inet | awk '{print $2}' | wc -w
   84  history
   85  ifconfig
   86  ifconfig | grep -i inet
   87  ifconfig | grep -i inet | awk '{print 2}'
   88  ifconfig | grep -i inet | awk '{print $2}'
   89  ifconfig | grep -w inet | awk '{print $2}'
   90  vi access.log
   91  cat access.log
   92  cat access.log | grep -i GET
   93  cat access.log | grep -i GET | awk '{print $1}'
   94  cat access.log | grep -w GET | awk '{print $1}'
   95  cat access.log | grep -i GET | awk '{print $1}'
   96  cat access.log | grep -i GET | awk '{print $1}' | unique
   97  cat access.log | grep -i GET | awk '{print $1}' | uniqu
   98  cat access.log | grep -i GET | awk '{print $1}' | uniq
   99  cat access.log | grep -i GET | awk '{print $1}' | uniq -u
  100  cat access.log | grep -i GET | awk '{print $1}' | uniq -d
  101  cat access.log | grep -i GET | awk '{print $1}' | uniq -u
  102  cat access.log | grep -i GET | awk '{print $1}' | uniq -c
  103  cat access.log | grep -i GET | awk '{print $1}' | sort | uniq -c
  104  cat access.log | grep -i GET | awk '{print $1}' | uniq -c | sort
  105  cat access.log | grep -i GET | awk '{print $1}' | uniq -c | sort -r
  106  cat access.log | grep -i GET | awk '{print $1}' | uniq -c | sort
  107  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -u | sort -r
  108  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -u | sort
  109  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -r
  110  cat access.log | grep -i GET | awk '{print $1}' | sort -o | uniq -c | sort -r
  111  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -r
  112  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -0
  113  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -r
  114  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort
  115  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -v
  116  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -V
  117  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -n -r
  118  cat access.log | grep -i GET | awk -
  119  cat access.log | grep -i GET | awk -F '-' '{print $1,$3}'
  120  cat access.log | grep -i GET | awk -F '-' '{print $1,$3}' | awk '{print $1,$4}'
  121  cat access.log | grep -i GET POST| awk -F '-' '{print $1,$3}' | awk '{print $1,$4}'
  122  cat access.log | grep -i GET,POST| awk -F '-' '{print $1,$3}' | awk '{print $1,$4}'
  123  cat access.log | grep -i GET | awk -F '-' '{print $1,$3}' | awk '{print $1,$4}'
  124  cat access.log | grep -i GET | awk -F '-' '{print $1,$3}' | awk '{print $1,$4}' | sort -r | uniq -c | sort -n -r
  125  cat access.log | grep -i POST | awk -F '-' '{print $1,$3}' | awk '{print $1,$4}' | sort -r | uniq -c | sort -n -r
  126  vi sum.txt
  127  cat sum.txt | grep abc
  128  cat sum.txt | grep abc | awk '{SUM+=$2}END{print SUM}'
  129  cat access.log | grep error
  130  history

6. Devops_Linux_Commands:
=========================
File Permissions:
-----------------
-rw-r--r--
-rw-    r--     r--
User - Group - Others

r --> read --> 4
w --> write --> 2
x --> executable --> 1
  --> nothing --> 0
  
umask default value --> 022

Default file permission --> 644
Default Directory/folder permission --> 755

umask value is used to reduce the permission
chmod is providing the permission

255 character leght

255 bytes
On Linux: The maximum length for a file name is 255 bytes. 
The maximum combined length of both the file name and path name is 4096 bytes.

How make it file immutable permanently?
========================================
sudo chattr +i /backups/passwd

sudo chattr +i sample.txt

How make it file mutable permanently?:
========================================
sudo chattr -i sample.txt

Install process:
----------------
sudo apt install packagename -y
sudo yum install pakcagename -yum

yum --> centos, ami linux, redhat
apt, apt-get --> ubuntu
pip install --> python
npm --> nodejs
apk add --> alpine

CTRL+A to come first

check a service is running or not:
----------------------------------
systemctl status httpd

service httpd status

Q) How to check listen port in system
Ans) [ec2-user@ip-172-31-10-164 ~]$ netstat
[ec2-user@ip-172-31-10-164 ~]$ netstat -nlpt

[ec2-user@ip-172-31-10-164 ~]$ history
    1  clear
    2  ls -ltr
    3  pwd
    4  du
    5  free
    6  top
    7  df
    8  netstat
    9  telnet
   10  yum install telnet
   11  sudo yum install telnet
   12  telnet
   13  w
   14  fdisk
   15  wc
   16  uptime
   17  man
   18  lostat
   19  iostat
   20  vmstat
   21  pwd
   22  sudo -i
   23  mkdir devops
   24  ls
   25  ls -l
   26  man ls
   27  whatis cp
   28  whatis ls
   29  whatis netsata
   30  whatis netstat
   31  cd devops/
   32  ls
   33  ls -ltr
   34  mkdir course
   35  cd cor
   36  cd course/
   37  pwd
   38  mkdir -p madhucourse/linux
   39  ls -ltr
   40  cd madhucourse/
   41  ls
   42  cd ..
   43  cd madhucourse/linux/
   44  cd
   45  cd -
   46  cd ../..
   47  pwd
   48  cd
   49  cd devops/
   50  ls
   51  touch sample.txt
   52  ll
   53  vi example.txt
   54  ll
   55  vi example.txt
   56  ls -li
   57  echo --> test1.txt
   58  ls -ltr
   59  echo "this is devops course"
   60  echo $USER
   61  env
   62  env | grep -i user\
   63  env | grep -i user
   64  env | grep -i USER
   65  env | grep USER
   66  vi sample.txt
   67  cat sample.txt
   68  cat sample.txt | grep devops
   69  cat sample.txt | grep -i devops
   70  ifconfig
   71  hostname
   72  vi hostname
   73  ifconfig | grep inet
   74  ifconfig | grep -w inet
   75  ifconfig | grep -w inet | awk 2
   76  ifconfig | grep -w inet | awk '{print $1}'
   77  ifconfig | grep -w inet | awk '{print $2}'
   78  ifconfig | grep -w inet | awk '{print $3}'
   79  ifconfig | grep -w inet | awk '{print $2}'
   80  ifconfig | grep -w inet | awk '{print $2}' |wc
   81  ifconfig | grep -w inet | awk '{print $2}' | wc -l
   82  ifconfig | grep -w inet | awk '{print $2}' | wc -c
   83  ifconfig | grep -w inet | awk '{print $2}' | wc -w
   84  history
   85  ifconfig
   86  ifconfig | grep -i inet
   87  ifconfig | grep -i inet | awk '{print 2}'
   88  ifconfig | grep -i inet | awk '{print $2}'
   89  ifconfig | grep -w inet | awk '{print $2}'
   90  vi access.log
   91  cat access.log
   92  cat access.log | grep -i GET
   93  cat access.log | grep -i GET | awk '{print $1}'
   94  cat access.log | grep -w GET | awk '{print $1}'
   95  cat access.log | grep -i GET | awk '{print $1}'
   96  cat access.log | grep -i GET | awk '{print $1}' | unique
   97  cat access.log | grep -i GET | awk '{print $1}' | uniqu
   98  cat access.log | grep -i GET | awk '{print $1}' | uniq
   99  cat access.log | grep -i GET | awk '{print $1}' | uniq -u
  100  cat access.log | grep -i GET | awk '{print $1}' | uniq -d
  101  cat access.log | grep -i GET | awk '{print $1}' | uniq -u
  102  cat access.log | grep -i GET | awk '{print $1}' | uniq -c
  103  cat access.log | grep -i GET | awk '{print $1}' | sort | uniq -c
  104  cat access.log | grep -i GET | awk '{print $1}' | uniq -c | sort
  105  cat access.log | grep -i GET | awk '{print $1}' | uniq -c | sort -r
  106  cat access.log | grep -i GET | awk '{print $1}' | uniq -c | sort
  107  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -u | sort -r
  108  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -u | sort
  109  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -r
  110  cat access.log | grep -i GET | awk '{print $1}' | sort -o | uniq -c | sort -r
  111  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -r
  112  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -0
  113  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -r
  114  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort
  115  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -v
  116  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -V
  117  cat access.log | grep -i GET | awk '{print $1}' | sort -r | uniq -c | sort -n -r
  118  cat access.log | grep -i GET | awk -
  119  cat access.log | grep -i GET | awk -F '-' '{print $1,$3}'
  120  cat access.log | grep -i GET | awk -F '-' '{print $1,$3}' | awk '{print $1,$4}'
  121  cat access.log | grep -i GET POST| awk -F '-' '{print $1,$3}' | awk '{print $1,$4}'
  122  cat access.log | grep -i GET,POST| awk -F '-' '{print $1,$3}' | awk '{print $1,$4}'
  123  cat access.log | grep -i GET | awk -F '-' '{print $1,$3}' | awk '{print $1,$4}'
  124  cat access.log | grep -i GET | awk -F '-' '{print $1,$3}' | awk '{print $1,$4}' | sort -r | uniq -c | sort -n -r
  125  cat access.log | grep -i POST | awk -F '-' '{print $1,$3}' | awk '{print $1,$4}' | sort -r | uniq -c | sort -n -r
  126  vi sum.txt
  127  cat sum.txt | grep abc
  128  cat sum.txt | grep abc | awk '{SUM+=$2}END{print SUM}'
  129  cat access.log | grep error
  130  history
  131  vi test3.txt
  132  ls -ltr
  133  sudo chattr +i sample.txt
  134  rm -rf sample.txt
  135  sudo chattr -i sample.txt
  136  rm -rf sample.txt
  137  ls -ltr
  138  yum install httpd
  139  sudo yum install httpd
  140  systemctl status httpd
  141  systemctl start httpd
  142  sudo systemctl start httpd
  143  systemctl status httpd
  144  netstat
  145  systemctl status http
  146  ls -s
  147  df
  148  df -h
  149  du -h -s
  150  ifconfig
  151  ifconfig | grep -i inet
  152  ifconfig | grep -i inet | awk '{print $2}'
  153  ifconfig | grep -w inet | awk '{print $2}'
  154  ls
  155  ll
  156  ifconfig | grep -w inet
  157  grep --help
  158  cat access.log
  159  cat access.log | grep -i GET
  160  cat access.log | grep -i GET | awk '{print $1}'
  161  cat access.log | grep -i GET | awk '{print $1}' | uniq -c
  162  cat access.log | grep -i GET | awk '{print $1}' | uniq -c | sort -r
  163  cat access.log | grep -i GET | awk '{print $1}' | uniq -c | sort -n -r
  164  cat access.log | grep -i GET | awk '{print $1}' |sort -r| uniq -c | sort -n -r
  165  cat access.log | grep -i POST | awk '{print $1}' |sort -r| uniq -c | sort -n -r
  166  cat access.log | grep -i GET | awk -F '-' '{print $1,$3}' | awk '{print $1,$4}'
  167  ls
  168  touch sample.txt
  169  ll
  170  ls -la
  171  cd /etc/
  172  ls
  173  vi profile
  174  cd
  175  umask 022
  176  vi sample1.txt
  177  ls -ltr
  178  chmod 666 sample1.txt
  179  ls -ltr
  181  cd /usr/lib
  182  ll
  183  cd
  184  cd /bin/
  185  ll
  186  cd /usr/local/bin/
  187  ll
  188  cd
  189  cd /usr/sbin/
  190  ll
  191  vi file.txt
  192  ll



7. Devops_Linux_Commands:
=========================
Softlink vs hardlink:
---------------------
ln  	-> Hardlink
ln -s	-> Softlink

service --> systemctl

lrwxrwxrwx  1 root root   30 Mar 26 17:36 sendmail -> /etc/alternatives/mta-sendmail
lrwxrwxrwx  1 root root   24 Mar 26 17:36 sendmail.postfix -> ../sbin/sendmail.postfix

ln file1 file1-hard


Hard link
---------
INODE value for hard link is SAME
Both the files talk to the INODE value
Hardlink file point to INODE value
If source file is deleted hardlink file also will  show data

Softlink
--------
INODE value for soft link is DIFFERENT
The files talk to each other
Softlink file direcly point to source value
If source file is deleted softlink file also will not show anything
It is useful to install any software/packages

Ping
wget 
curl --> It is used for download, upload, delete purpose
         it supports all http service
		 GET,POST,DELETE,PUT
useradd
passwd

wget url -P /path/to/folder

curl -o target/path/filename URL

curl --create-dirs -O --output-dir /tmp/receipes https://example.com/pancakes.jpg

curl -L -o target/path/filename URL -> curl -L -o ~/tomcat/tomcat.tar.gz <tomcat URL>

[ec2-user@ip-172-31-45-249 ~]$ history
    1  vi file2
    2  ln -s file2 soft-file2
    3  cat file2
    4  cat soft-file2
    5  vi soft-file2
    6  cat soft-file2
    7  cat file2
    8  vi file1
    9  ln file1 hard-file1
   10  cat hard-file1
   11  cat file
   12  cat file1
   13  vi hard-file1
   14  cat file1
   15  ls -ltri
   16  rm -rf file2
   17  ls -ltri
   18  cat soft-file2
   19  rm -rf file1
   20  cat hard-file1
   21  ls -ltr
   22  vi file2
   23  ls -ltri
   24  rm -rf soft-file2
   25  ls -ltri
   26  cat file2
   27  history
   28  ping google.com
   29  ping facebook.com
   30  host www.google.com
   31  history

8. DevOps_linux_commands_ssh_keygen:
====================================

Useful site for linux commands:
------------------------------
https://www.geeksforgeeks.org/introduction-to-linux-operating-system/

-> Password less authentication:
--------------------------------
- If we want connect other machine
	1. take public key of our machine
	
	2. paste our public key to another system in authorization_keys
	
	3. the try to access using ssh commands		
			ssh-keygen ec2-user@ip-172-31-10-164

adduser madhu
   33  sudo adduser madhu
   34  sudo useradd mahesh
   35  cat /etc/passwd
   36  cat /etc/passwd | awk -F ':' {print $1}
   37  cat /etc/passwd | awk -F ':' '{print $1}'
   38  cut -f 1 -d: /etc/passwd
   39  passwd madhu
   40  sudo passwd madhu
   41  su -madhu
   42  su - madhu
   43  cd ~/.ssh
   44  ls
   45  vi authorized_keys
   46  cd
   47  cd ~/.ssh
   48  vi authorized_keys
   49  cd
   50  ll
   51  ssh ec2-user@65.2.35.185
   52  cd ~/.ssh/
   53  ll
   54  ssh-keygen
   55  ll
   56  cat id_rsa.pub
   57  ssh ec2-user@65.2.35.185
   58  historu
   59  history

 ssh madhu@13.234.232.233
    2  ssh-keygen
    3  cat /home/ec2-user/.ssh/id_rsa
    4  vi /home/ec2-user/.ssh/id_rsa
    5  cd /home/ec2-user/.ssh/
    6  ll
    7  cat id_rsa.pub
    8  ssh madhu@13.234.232.233
    9  cat id_rsa.pub
   10  ssh ec2-user@13.234.232.233
   11  ll
   12  vi authorized_keys
   13  history
     date
   15  date R
   16  date -R
   17  cal
   19  cal -y
   18  cd
   20  cal -q
   21  cal -Q
   22  cal -m
   23  cal -t

14  date
   15  date R
   16  date -R
   17  cal
   18  cd
   19  cal -y
   20  cal -q
   21  cal -Q
   22  cal -m
   23  cal -t
   24  history
   25  cal 2020
   26  seq
   27  seq 56789
   28  seq 7
   29  seq -5 5
   30  bc
   31  seq 1 2 20
   32  seq -s ' ' 1 10
   33  man
   34  whatis
   35  hi this is first line
   36  pwd
   37  ls -a
   38  ls -lh
   39  ls -ld
   40  ls -i
   41  ls -s
   42  df


9. Devops_Linux_Commands:
=========================
password less authentication
----------------------------
connect ssh with shortcut:
--------------------------
redirect option > >>
--------------------
cron job
--------
password less authentication
----------------------------
1. Developer as for machine access
	. create user <adduser>
	. su - <username>
    . create authorized_keys file
	. ask the developer provide public key
	. add that key into authorized_keys
	. change permission chmod 400 authorized_keys
	. ssh madhu@<IP address>


connect ssh with shortcut:
--------------------------
~/.ssh/

config - file

Host jenkins
	HostName 65.2.124.174
	User ec2-user
	Identifyfile /droves/f/Devops/AWSKey/jms.pem
	SeverAliveInterval 10
	
1.What is Zombie process

[ec2-user@ip-172-31-33-153 ~]$ ps aux | grep 'Z'
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
ec2-user 32642  0.0  0.0 119420   908 pts/0    S+   11:03   0:00 grep --color=auto Z

[ec2-user@ip-172-31-33-153 ~]$ kill -9 32642

2. from whate the top command data will come up
   ans) [ec2-user@ip-172-31-33-153 ~]$ cd /proc/
	     [ec2-user@ip-172-31-33-153 proc]$ vi cpuinfo
    memory utilization     
		 [ec2-user@ip-172-31-33-153 ~]$ df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        482M     0  482M   0% /dev
tmpfs           492M     0  492M   0% /dev/shm
tmpfs           492M  488K  492M   1% /run
tmpfs           492M     0  492M   0% /sys/fs/cgroup
/dev/xvda1      8.0G  1.4G  6.7G  18% /
tmpfs            99M     0   99M   0% /run/user/1000
tmpfs            99M     0   99M   0% /run/user/0

=> cpu utilization => "top" command
=> [ec2-user@ip-172-31-33-153 ~]$ free -kh
              total        used        free      shared  buff/cache   available
Mem:           983M         96M        413M        488K        473M        744M
Swap:            0B          0B          0B

=> [ec2-user@ip-172-31-33-153 ~]$ uptime
 10:58:09 up  1:26,  1 user,  load average: 0.00, 0.00, 0.00

0.00, 0.00, 0.00 => 1 min(.1), 5 min, 15 mins load


Redirector (>) :
=================
To store contenct in file

[ec2-user@ip-172-31-33-153 ~]$ echo 'this is devops class' > test.txt


Goto volume -> take volume -> crate new intance and that volume

-> create Image for instance -> goto AMI's -> go to instances -> goto lanuncinstance and select my AMI's

cd ~/.ssh/
    3  ll
    4  ssh-keygen
    5  ll
    6  cat id_rsa.pub
    7  ssh ec2-user@65.0.95.72
    8  adduser madhu
    9  sudo adduser madhu
   10  sudo passwd madhu
   11  usermod -aG sudo username
   12  cd
   13  sudo usermod -aG sudo username
   14  sudo -i
   15  ll
   16  cd ~/.ssh/
   17  ll
   18  vi authorized_keys
   19  exit

1  cd ~/.ssh/
    2  ll
    3  vi authorized_keys
    4  ssh ec2-user@65.0.95.72
    5  ll
    6  cd
    7  ll
    8  su - madhu
    9  useradd madhu
   10  sudo useradd madhu
   11  sudo passwd madhu
   12  su - madhu
   13  uptime
   14  top
   15  cd /proc/
   16  ll
   17  vi cpuinfo
   18  cd
   19  df -h
   20  free -kh
   21  uptime
   22  ps
   23  ps aux | grep 'Z'
   24  echo 'this is devops class' > test.txt
   25  cat test.txt
   26  ps aux >test1.txt
   27  cat test1.txt
   28  vi test.txt
   29  echo 'this is linux' >> test.txt
   30  cat test.txt

10. Devops_Linux_Cronjob_Vi_editor_shortcuts
=============================================
https://scotch.io/tutorials/how-to-create-an-ssh-shortcut

Q) col1,col2
	1,10
	3,11
	10,34
	34,21
	
I want print morethan 10 values in col1

A) [ec2-user@ip-172-31-45-249 ~]$ cat sample.txt | awk -F ',' '{print $1}'| awk '$1>10'

https://dzone.com/devops-tutorials-tools-news

https://devops.com/sign-up-for-our-newsletter-thank-you/

Cronjob(Scheduler):
===================
Script --> send a logs to a client

  * 	  * 	 * 		  * 	    *
Mint	Hours	Day		Month  Day of the week
0-59	0-23	1-31	1-12	0-7

0 0 * * * sh logpurge.sh 2>&1 output.log &

https://crontab.guru/#1_3-10_*_*_MON-FRI

1) How to run a job in back ground
 using "&"
logpurge means deleting logs
0 input
1 stdinput
2 stderror

5  cat sample.txt | awk -F ',' '{print $1}'| awk '$1>10'
   76  uptime
   77  crontab -e
   78  sudo yum install crontabs
   79  crontab -l
   80  crontab -e
   81  vi hello.sh
   82  sh hello.sh
   83  crontab -e
   84  pwd
   85  crontab -e
   86  ll
   87  cat mygreeting.log
   88  sh hello.sh
   89  vi hello.sh
   90  ll
   91  cat mygreeting.log
   92  crontab -l
   93  crontab --help
   94  vi data.txt

11. DevOps_Linux_issues_questions_discussion:
=============================================
create sudo user in ubuntu:
---------------------------
https://www.digitalocean.com/community/tutorials/how-to-create-a-sudo-user-on-ubuntu-quickstart
https://linuxize.com/post/how-to-create-a-sudo-user-on-ubuntu/

12. DevOps_Linux_shell_script:
==============================
go to root user - 
cron tab available in = /var/spool/cron/
[root@ip-172-31-45-249 ~]# cd /var/spool/cron/
-rw------- 1 ec2-user ec2-user 60 Apr 21 12:12 ec2-user

Migration:
==========
one server to another server

Each user crontab files moved from one server to another server

Version upgradation


-> if system not required

https://superuser.com/questions/597168/total-disk-usage-for-a-particular-user

 uptime
   77  crontab -e
   78  sudo yum install crontabs
   79  crontab -l
   80  crontab -e
   81  vi hello.sh
   82  sh hello.sh
   83  crontab -e
   84  pwd
   85  crontab -e
   86  ll
   87  cat mygreeting.log
   88  sh hello.sh
   89  vi hello.sh
   90  ll
   91  cat mygreeting.log
   92  crontab -l
   93  crontab --help
   94  vi data.txt
   95  history
   96  cat /etc/group
   97  crontab -l
   98  crontab -e
   99  sudo -i
  100  du -h ~
  101  du -h ~ec2-user
  102  cat /etc/passwd

reboot - 
how to shoutdown particual time - shutdown


Scheduling a shutdown
To shutdown run the command:

sudo shutdown -P +60
That will wait 60 mins before starting the shutdown sequence.

Q) what is at vs cron

at - it useful to run a job only one time
cron - run a job as per schedule

https://www.geeksforgeeks.org/at-command-in-linux-with-examples/#:~:text=at%20command%20is%20a%20command,any%20time%20in%20the%20future.&text=could%20be%20used%20with%20at%20command%20to%20schedule%20a%20job.

sudo apt-get update
sudo apt-get install at
at Monday +20 minutes

Shell script examples:
----------------------
#!/bin/bash
#! - shebang line
/bin/bash - in bin bash is installed

:' multiple line comment'
-----------------------------------------------------
[ec2-user@ip-172-31-45-249 ~]$ vi addition.sh
#!/bin/bash
# This is addition

echo "enter a value"
read a
echo "enter b value"
read b

((sum = $a+$b))

echo $sum
---------------------------------------------------

$# = no.of arguments passed
$* = it will show values
$? = previous command is true it will display 0 else 1
$1 = To read particual argument (first argument)
$2 = To read particual argument (second argument)

set -x to trouble shoot = it shows how many lines are executed

[ec2-user@ip-172-31-45-249 ~]$ cat expressions.sh
#!/bin/bash

if [ $# -ne 2 ]
then
        echo "USAGE: sh expression.sh <arg1> <arg2>"
        exit 1
fi
echo 'this is $# :' $#
echo 'this is $* :' $*
echo 'this is $? :' $?
[ec2-user@ip-172-31-45-249 ~]$ sh expressions.sh devops madhu
this is $# : 2
this is $* : devops madhu
this is $? : 0

[ec2-user@ip-172-31-45-249 ~]$ cat condition.sh
#!/bin/sh
false
result=$?
if [ $result = 0 ];then
  echo "this condition is true"
 else
  echo "this condition is false"
fi
-----------------------------------------------------
[ec2-user@ip-172-31-45-249 ~]$ sh condition.sh
this condition is false
[ec2-user@ip-172-31-45-249 ~]$ vi condition.sh
[ec2-user@ip-172-31-45-249 ~]$ cat condition.sh
#!/bin/sh
true
result=$?
if [ $result = 0 ];then
  echo "this condition is true"
 else
  echo "this condition is false"
fi

[ec2-user@ip-172-31-45-249 ~]$ sh condition.sh
this condition is true
-----------------------------------------------------
https://linuxhint.com/30_bash_script_examples/
https://www.macs.hw.ac.uk/~hwloidl/Courses/LinuxIntro/x961.html
https://github.com/epety/100-shell-script-examples/blob/master/001-inpath.sh
https://www.ubuntupit.com/simple-yet-effective-linux-shell-script-examples/ 

13. DevOps_Linux_shell_script:
==============================
https://github.com/PacktPublishing/Mastering-Linux-Shell-Scripting-Second-Edition

age = 18 
age > 18
eligible for vote 

[ec2-user@ip-172-31-45-249 ~]$ cat voting.sh
#!/bin/bash

#echo "Please enter your age"
#read age
#age=18

if [ $# -ne 1 ]
then
        echo "USAGE: sh voting.sh <argvalue>"

        exit 1
fi
age=$1

if [ $age -ge 18 ];
then
        echo "You are eligible for vote"
else
        echo "You are not eligible for vote"
fi
[ec2-user@ip-172-31-45-249 ~]$ sh voting.sh
USAGE: sh voting.sh <argvalue>
[ec2-user@ip-172-31-45-249 ~]$ sh voting.sh 4
You are not eligible for vote
[ec2-user@ip-172-31-45-249 ~]$ cat andcondition.sh
#!/bin/bash
echo "enter username"
read username
echo "enter password"
read password

if [[ $username == "admin" && $password == "admin123" ]];
then
        echo "The username and password are correct.. login successful"
else
        echo "The username and password are wrong.."
        fi

[ec2-user@ip-172-31-45-249 ~]$ sh andcondition.sh
enter username
admin
enter password
admin123
The username and password are correct.. login successful
[ec2-user@ip-172-31-45-249 ~]$ cat orcondition.sh
#!/bin/bash
echo "enter marks"
read marks
echo "enter scale"
read scale
if [[ $marks -eq 35 || $scale -ge 6 ]];
then
        echo "You passed the exam"
else
        echo "You failed the exam"
        fi

[ec2-user@ip-172-31-45-249 ~]$ ./orcondition.sh
enter marks
43
enter scale
53
You passed the exam

-------------
[ec2-user@ip-172-31-45-249 ~]$ cat mobile.sh
#!/bin/bash
echo "which mobile you want"
read mobile
if [ $mobile == "Nokia" ];
then
        echo "budget phone its very strong phone"
elif [ $mobile == "Samsung" ];
then
        echo "its nice phone"
elif [ $mobile == "mi" ];
then
        echo "very hanging phone"
else
        echo "go for other choice"
fi

[ec2-user@ip-172-31-45-249 ~]$ sh mobile.sh
which mobile you want
mi
very hanging phone
[ec2-user@ip-172-31-45-249 ~]$ cat mobile_swith.sh
#!/bin/bash
echo "which mobile you want"
read mobile
case $mobile in
nokia)
echo "budget phone its very strong phone";;
samsung)
echo "its nice phone";;
mi)
echo "very hanging phone";;
*)
echo "go for other choice";;
esac
[ec2-user@ip-172-31-45-249 ~]$ sh mobile_swith.sh
which mobile you want
mi
very hanging phone
--------------

14. DevOps_Linux_shell_script:
==============================
For loop
While loop
strings


print 1 to 10 numbers
---------------------
[ec2-user@ip-172-31-45-249 ~]$ cat forloop.sh
#!/bin/bash

for (( counter=1; counter<=10; counter++ ))
do
echo -n "$counter "
done

printf "\n"
[ec2-user@ip-172-31-45-249 ~]$ sh forloop.sh
1 2 3 4 5 6 7 8 9 10
----------------------------------
[ec2-user@ip-172-31-45-249 ~]$ cat reverseforloop.sh
#!/bin/bash

for (( counter=$1; counter>0; counter-- ))
do
echo -n "$counter "
done

printf "\n"
[ec2-user@ip-172-31-45-249 ~]$ sh reverseforloop.sh 5
5 4 3 2 1
-------------------------------
[ec2-user@ip-172-31-45-249 ~]$ cat whileloop.sh
#!/bin/bash
i=0

while [ $i -le 2 ]
do
echo Number: $i
((i++))
done
[ec2-user@ip-172-31-45-249 ~]$ sh whileloop.sh
Number: 0
Number: 1
Number: 2
------------------------------
String:
-------
[ec2-user@ip-172-31-45-249 ~]$ cat strings.sh
#!/bin/bash
firstname="Madhu"
lastname="Sudhan"
echo "$firstname $lastname"
output=$firstname$lastname
echo ${output:0:7}
[ec2-user@ip-172-31-45-249 ~]$ ./strings.sh
Madhu Sudhan
MadhuSu
--------------------------
Reversing a string:
-------------------
[ec2-user@ip-172-31-45-249 ~]$ cat reversestring.sh
#!/bin/bash
name="Mahesh"
reverse=""
len=${#name}
for(( i=$len-1; i>=0; i-- ))
do
        reverse="$reverse${name:$i:1}"
done
echo $reverse
[ec2-user@ip-172-31-45-249 ~]$ sh reversestring.sh
hsehaM
----------------------------------
Q) Creating configuration files in different environments
[ec2-user@ip-172-31-45-249 ~]$ cat env_forloop.sh
#!/bin/bash
#file="file1.txt"
for var in "dev" "predev" "staging" "prod"
do
        touch "myfile_$var.txt"
done
[ec2-user@ip-172-31-45-249 ~]$ sh env_forloop.sh
==> it creates three files
-------------------------
15. DevOps_Linux_shell_script:
==============================
Functions
sed
[ec2-user@ip-172-31-45-249 ~]$ cat samplet.txt
madhu sudhan reddy y b
madhu sudhan reddy y b
madhu sudhan reddy y b
madhu sudhan reddy y b
[ec2-user@ip-172-31-45-249 ~]$ cat samplet.txt | uniq | tr ' ' '\n' | sort -u
b
madhu
reddy
sudhan
y
---------
Ans)  find . -printf "%p %f\n" | sort -f -k2 | uniq -Di -fi

Q) both direcotries have common files

SED Command: i =  -i[SUFFIX], --in-place[=SUFFIX]
                 edit files in place (makes backup if SUFFIX supplied)

------------
[ec2-user@ip-172-31-45-249 ~]$ sed 's/madhu/Mahesh/g' samplet.txt
Mahesh sudhan reddy y b
Mahesh sudhan reddy y b
Mahesh sudhan reddy y b
Mahesh sudhan reddy y b
[ec2-user@ip-172-31-45-249 ~]$ vi samplet.txt
[ec2-user@ip-172-31-45-249 ~]$ sed -i 's/madhu/Mahesh/g' samplet.txt
[ec2-user@ip-172-31-45-249 ~]$ vi samplet.txt
[ec2-user@ip-172-31-45-249 ~]$ cat samplet.txt
Mahesh sudhan reddy y b
Mahesh sudhan reddy y b
Mahesh sudhan reddy y b
Mahesh sudhan reddy y b

tree - command - it will show the tree of directry and files

Q) what is the purpose of AWK and SED command

Q) Create file with current date
https://stackoverflow.com/questions/48270960/how-to-create-a-file-with-todays-date-in-the-filename

[ec2-user@ip-172-31-45-249 ~]$ touch "test2_$(date +"%F %T")"

[ec2-user@ip-172-31-45-249 ~]$ cat functiontest.sh
#!/bin/bash
function data()
{
echo "Learn Devops"
}
data
[ec2-user@ip-172-31-45-249 ~]$ sh functiontest.sh
Learn Devops
[ec2-user@ip-172-31-45-249 ~]$ cat sumfunction.sh
#!/bin/bash
function sum()
{
area=$(($1 + $2))
echo "Area is : $area"
}
sum 10 20
[ec2-user@ip-172-31-45-249 ~]$ sh sumfunction.sh
Area is : 30
[ec2-user@ip-172-31-45-249 ~]$ cat returnfunction.sh
#!/bin/bash
function greeting() {

str="Hello, $name"
echo $str

}

echo "Enter your name"
read name

val=$(greeting)
echo "Return value of the function is $val"
[ec2-user@ip-172-31-45-249 ~]$ sh returnfunction.sh
Enter your name
Mahesh
Return value of the function is Hello, Mahesh

----------------------------------------------------------
16. DevOps_Linux_Real_time_interview_Questions:
===============================================


17. Git_introduction_setup:
===========================
git
github --> 70% by developer
GIT - Git is a command line interface

Version Control Systems:
------------------------
two types of version control system

1. Centralized version control system - if it goes down we can not pull, push, clone.. we are facing single point of failure (SVN)
2. Distributed version control system - overcome the single point of failure

SVN/cvs 																Git different
-----------------                                                    -------------------
centralized remote repository 										     dvcs
single point of failure											 No single point of failure
All commands are executed in central repository					some commands are executed in central repository					 
We must have internet connectivity								No need of internet till we push the code


-> Create git project
----------------------
1. create one folder - first
2. create a file inside folder - 
3. convert your folder to git project - using git init
    changes username mail
	git config --global --edit
	git config --global --name "Mahesh"
	git config --global --email "bgnanesh6@gmail.com"
4. check status --> git status
5. commit your changes --> git commit -m "<enter message>"
6. check your destination path/origin path
7. create github account
8. create same name in report repo(first)
9. added destination (git remote add origin <url>)
10. git push origin master


git remote add origin https://github.com/bgnanesh56/first.git
#git remote set-url origin https://github.com/bgnanesh56/first.git

git mail id - bgnanesh6@gmail
User name - bgnanesh56
password - Mahesh@12345678

[ec2-user@ip-172-31-34-101 first]$ history
    1  git --version
    2  yum instal git -y
    3  yum install git -y
    4  sudo yum install git -y
    5  git --version
    6  git --help
    7  show
    8  mkdir firt
    9  ll
   10  rm firt/
   11  rm -rf firt/
   12  ll
   13  mkdir first
   14  cd first/
   15  vi sample.txt
   16  ll
   17  ls -ltra
   18  git init
   19  ls -ltra
   20  cd .git/
   21  ll
   22  cd ..
   23  git status
   24  git add .
   25  git status
   26  git commit -m "added sample file"
   27  git log
   28  git config --global --edit
   29  git log
   30  git push origin master
   31  git remote -v
   32  git remote add origin https://github.com/bgnanesh56/first.git
   33  git remote -v
   34  git push origin master
   35  vi example.txt
   36  git status
   37  git add .
   38  git status
   39  git commint -m "creted example filewq"
   40  git log
   41  git comint -m "creted example file"
   42  git status
   43  git commit -m "added example file"
   44  git status
   45  git log
   46  git push origin master

18. Git_clone_fork_mergeconflicts:
==================================
microsoft acquired

1.same project
2. working with different people
3. passwordless
4. clone
5. fork

ls -ld /tmp
------ 20 ---- ---- <filesize> <date> /tmp

[ec2-user@ip-172-31-34-101 ~]$ ls -ld /tmp
drwxrwxrwt 8 root root 172 May  3 10:13 /tmp

what is sticky bit and what is tmp dir has special permission?

1. working area
2. 

48  cd
   49  ll
   50  sudo mkdir second
   51  cd second/
   52  ll
   53  git init
   54  sudo git init
   55  ls -ltra
   56  touch file1.txt
   57  ll
   58  vi file1.txtx
   59  vi file1.txt
   60  sudo vi file1.txt
   61  git status
   62  git add .
   63  cd
   64  ll
   65  rm -rf second/
   66  sudo rm -rf second/
   67  ll
   68  su -i
   69  sudo -i
   70  ls
   71  mkdir second
   72  ls
   73  cd second/
   74  ll
   75  vi file2.txt
   76  git init
   77  git status
   78  git add .
   79  git commit -m "Added file2 folder"
   80  git status
   81  git push origin master
   82  git remote add origin https://github.com/bgnanesh56/first.git
   83  git push origin master
   84  git log
   85  git remote -v
   86  git push origin master
   87  git remote set-url origin https://github.com/bgnanesh56/second.git
   88  git push origin master
   89  ls -ld /tmp
   90  ll
   91  cd second/
   92  ls -ltra
   93  git log
   94  vi today.txt
   95  git status
   96  git add .
   97  git commit -m "today file created"
   98  git push origin master
   99  git log
  100  git remote -v
  101  ll
  102  cd second/
  103  ll
  104  vi today.txt
  105  git status
  106  git diff
  107  git add .
  108  ll
  109  git status
  110  git commit -m "updated todays fiel"
  111  git status
  112  git push origin master
  113  git log
  114  git log --pretty=oneline
  115  git remote -v
  116  cd ~/.ssh/
  117  ll
  118  ssh-keygen
  119  ls -ltra
  120  cat id_rsa.pub
  121  cd
  122  cd second/
  123  ll
  124  vi today.txt
  125  git status
  126  gid add .
  127  git add .
  128  git commit -m "added third line"
  129  git push origin master
  130  git remote set-url origin git@github.com:bgnanesh56/second.git
  131  git push origin master
  132  git clone git@github.com:bgnanesh56/existingone.git
  133  ll
  134  cd
  135  git clone git@github.com:bgnanesh56/existingone.git
  136  ll
  137  cd existingone/
  138  ls -ltra
  139  git remote -v
  140  ls -ltra
  141  vi myfile.txt
  142  git status
  143  git add .
  144  git commit -m "new file myfile created"
  145  git branch
  146  git push origin master
  147  git push origin main
  148  cd
  149  cd second/
  150  git branch
  151  cd
  152  cd e
  153  ll
  154  cd existingone/
  155  ll

Git fork
---------

19. Git_branching_tagging:
==========================
SLA - Software License Agreement - Service Level Agreement

predev,dev,acc,train,prod
predev,dev,staging,preprod,prod

Tags:
=====
laightweight tag - git tag v1.0
annotated tad - git tag -a v1.1 -m "<reason for releases>"

20. Git_merge_vs_rebase_organization_pull_request:
==================================================
git merge
git merge squash
git rebase
git cherrypick

Fast-forward merging:
========================
- There were no commits in master branch before merging feature branch with master branch 

Fast-forward recursive strategy:
================================
- There were some commits in master branch before merging feature branch with master branch 
- In this scenario while doing merge with master branch one new commit will create in master branch which is called GIT MERGE SQUASH.
- SQUASH means combining multiple commits into single commit

Merge made by the 'recursive' strategy.

git merge --squash feature1

[ec2-user@ip-172-31-34-101 second]$ git merge --squash feature2
Squash commit -- not updating HEAD
Automatic merge went well; stopped before committing as requested

Rebase:
-------
[ec2-user@ip-172-31-34-101 second]$ git rebase feature3
First, rewinding head to replay your work on top of it...
Fast-forwarded master to feature3.


21. Git_cherry_pick_ammend_git_undoing:
=======================================
Git Cherrypick:
---------------
one kind of merging only
what ever commit id if you want to add that file to master we will use cherry pick

[ec2-user@ip-172-31-34-101 third]$ git cherry-pick 8b054c1

Git undoing:
------------

Working Area ==> git add --> Staging/index -->git commit --> commit history --> git push
undo ur changes
git checkout -- before git add 

[ec2-user@ip-172-31-34-101 third]$ git checkout sample2.txt
Updated 1 path from the index

git reset 
	=> soft = only latest commit msg will remove, the changes are still avilable
	=> mixed = default option -> it will delete in index and committed area but the data won't change
	=> hard = it will delete all the areas as well as data also
	
git revert - it will create one commit for one delete and new commit for new changes

Ammend:
=======
To rename/modify the git commit message

in branching rules we will not allow the user to force push

git push -f origin master

22. Git_interview_questions:
-----------------------------
what are the files we do not want push into git hub we keep then in .gitignore file

 1  git --version
    2  yum instal git -y
    3  yum install git -y
    4  sudo yum install git -y
    5  git --version
    6  git --help
    7  show
    8  mkdir firt
    9  ll
   10  rm firt/
   11  rm -rf firt/
   12  ll
   13  mkdir first
   14  cd first/
   15  vi sample.txt
   16  ll
   17  ls -ltra
   18  git init
   19  ls -ltra
   20  cd .git/
   21  ll
   22  cd ..
   23  git status
   24  git add .
   25  git status
   26  git commit -m "added sample file"
   27  git log
   28  git config --global --edit
   29  git log
   30  git push origin master
   31  git remote -v
   32  git remote add origin https://github.com/bgnanesh56/first.git
   33  git remote -v
   34  git push origin master
   35  vi example.txt
   36  git status
   37  git add .
   38  git status
   39  git commint -m "creted example filewq"
   40  git log
   41  git comint -m "creted example file"
   42  git status
   43  git commit -m "added example file"
   44  git status
   45  git log
   46  git push origin master
   47  history
   48  cd
   49  ll
   50  sudo mkdir second
   51  cd second/
   52  ll
   53  git init
   54  sudo git init
   55  ls -ltra
   56  touch file1.txt
   57  ll
   58  vi file1.txtx
   59  vi file1.txt
   60  sudo vi file1.txt
   61  git status
   62  git add .
   63  cd
   64  ll
   65  rm -rf second/
   66  sudo rm -rf second/
   67  ll
   68  su -i
   69  sudo -i
   70  ls
   71  mkdir second
   72  ls
   73  cd second/
   74  ll
   75  vi file2.txt
   76  git init
   77  git status
   78  git add .
   79  git commit -m "Added file2 folder"
   80  git status
   81  git push origin master
   82  git remote add origin https://github.com/bgnanesh56/first.git
   83  git push origin master
   84  git log
   85  git remote -v
   86  git push origin master
   87  git remote set-url origin https://github.com/bgnanesh56/second.git
   88  git push origin master
   89  ls -ld /tmp
   90  ll
   91  cd second/
   92  ls -ltra
   93  git log
   94  vi today.txt
   95  git status
   96  git add .
   97  git commit -m "today file created"
   98  git push origin master
   99  git log
  100  git remote -v
  101  ll
  102  cd second/
  103  ll
  104  vi today.txt
  105  git status
  106  git diff
  107  git add .
  108  ll
  109  git status
  110  git commit -m "updated todays fiel"
  111  git status
  112  git push origin master
  113  git log
  114  git log --pretty=oneline
  115  git remote -v
  116  cd ~/.ssh/
  117  ll
  118  ssh-keygen
  119  ls -ltra
  120  cat id_rsa.pub
  121  cd
  122  cd second/
  123  ll
  124  vi today.txt
  125  git status
  126  gid add .
  127  git add .
  128  git commit -m "added third line"
  129  git push origin master
  130  git remote set-url origin git@github.com:bgnanesh56/second.git
  131  git push origin master
  132  git clone git@github.com:bgnanesh56/existingone.git
  133  ll
  134  cd
  135  git clone git@github.com:bgnanesh56/existingone.git
  136  ll
  137  cd existingone/
  138  ls -ltra
  139  git remote -v
  140  ls -ltra
  141  vi myfile.txt
  142  git status
  143  git add .
  144  git commit -m "new file myfile created"
  145  git branch
  146  git push origin master
  147  git push origin main
  148  cd
  149  cd second/
  150  git branch
  151  cd
  152  cd e
  153  ll
  154  cd existingone/
  155  ll
  156  history
  157  cd
  158  du
  159  top
  160  iostat
  161  df -h
  162  du -h
  163  du -h -s
  164  umask
  165  top
  166  ps
  167  top
  168  ps
  169  git config --list
  170  ps -ef | grep init
  171  touch passbook.txt
  172  ls -l passbook.txt
  173  > book1.txt
  174  ll
  175  ls -l
  176  ll
  177  cd second/
  178  git log
  179  git branch -l
  180  git branch --list
  181  git branch -a
  182  git branch feature
  183  git branch --list
  184  git branch -a
  185  git branch feature
  186  git checkout feature
  187  git branch -a
  188  git log
  189  vi feature.txt
  190  git status
  191  cd
  192  cd existingone/
  193  git branch
  194  git status
  195  cd ..
  196  ll
  197  cd second/
  198  ll
  199  rm -rf existingone/
  200  git status
  201  git add .
  202  git commit -m "added feature file"
  203  git status
  204  git log
  205  ll
  206  git push origin feature
  207  ll
  208  git branch
  209  vi merge.txt
  210  git status
  211  git add .
  212  git commit -m "created merge file"
  213  git push origin feature
  214  git branch -l
  215  git checkout master
  216  git branch
  217  git merge feature
  218  git log
  219  git push origin master
  220  git push origin main
  221  git status
  222  git checkout feature
  223  git status
  224  git checkout master
  225  git push origin master
  226  git fetch origin master
  227  ll
  228  git push origin master
  229  git merge feature
  230  git pull origin master
  231  git push origin master
  232  git branch
  233  git branch -d feature
  234  git push origin -d feature
  235  git branch -a
  236  git checkout -b feature
  237  git branch -a
  238  vi newfile.txt
  239  git add .
  240  git commit -m "newfile added"
  241  git push origin feature
  242  ll
  243  git push origin feature
  244  git checkout master
  245  git branch -d feature
  246  git branch -D feature
  247  git branch
  248  ls -ltr
  249  git pull origin master
  250  git status
  251  ll
  252  git log
  253  git tag --list
  254  git tag v0.1
  255  git tag --list
  256  git tag -a v0.2 -m "Main release"
  257  git tag --list
  258  git log
  259  git tag v0.01 26bbaf70cc6245fe985fc40783e1b24bd0ee79d4
  260  git tag -l
  261  git log
  262  git push origin tag v0.01
  263  git push --tags
  264  git tag -l
  265  git tag -d v0.01
  266  git push origin -d :ref/tags/v0.01
  267  git push origin -d :refs/tags/v0.01
  268  git tag -d v0.01
  269  git tag -l
  270  git push origin -d :refs/tags/v0.01
  271  git push origin :refs/tags/v0.01
  272  cd second/
  273  git branch -l
  274  git branch -a
  275  git log
  276  git checkout -b feature1
  277  git branch
  278  git log
  279  git branch
  280  vi pastforwarding.txt
  281  git add .
  282  git commit -m "pastforwarding file created"
  283  git log
  284  vi pastforwarding.txt
  285  git add .
  286  git commit -m "pastforwarding file updated"
  287  git log
  288  git checkout master
  289  git branch
  290  git log
  291  ll
  292  git merge feature1
  293  git log
  294  git branch
  295  git checkout feature1
  296  vi pastforwarding.txt
  297  git add .
  298  git commit -m "fast-forwarding updated"
  299  vi pastforwarding.txt
  300  git add .
  301  git commit -m "fast-forwarding recusive stratgy"
  302  git log
  303  git checkout master
  304  ll
  305  vi test2.txt
  306  git add .
  307  git commit -m "test2 file created"
  308  vi test2.txt
  309  git add .
  310  git commit -m "test2 file updated"
  311  git log
  312  git branch
  313  git merge feature1
  314  git log
  315  git log --pretty=oneline
  316  git branch
  317  git checkout -b feature2
  318  git log
  319  git branch
  320  vi madhu.txt
  321  git add .
  322  git commit -m "created madhu file"
  323  vi m
  324  vi madhu.txt
  325  git add .
  326  git commit -m "updated madhu file"
  327  git log
  328  git checkout master
  329  git log
  330  ll
  331  vi file2.txt
  332  git add .
  333  git commit -m "updated file2"
  334  vi file2.txt
  335  git add .
  336  git commit -m "updated file2 second time"
  337  git status
  338  git merge --squash feature2
  339  git log
  340  q
  341  git status
  342  git commit -m "squashing"
  343  git log
  344  git log --oneline
  345  ls -ltr
  346  git branch
  347  git checkout -b feature3
  348  git log
  349  git branch
  350  vi punu.txt
  351  git add .
  352  git commit -m "f7"
  353  vi punu.txt
  354  git add .
  355  git commit -m "f8"
  356  git status
  357  git checkout master
  358  l
  359  ll
  360  vi loki.txt
  361  git add .
  362  git commit -m "b5"
  363  vi loki.txt
  364  git add .
  365  git commit -m "b6"
  366  git log
  367  git checkout feature3
  368  git log
  369  git rebase master
  370  git log
  371  git checkout master
  372  git rebase feature3
  373  git log
  374  ll
  375  git log
  376  cd
  377  ll
  378  mkdir third
  379  cd third/
  380  vi sample2.txt
  381  git init
  382  ls -ltra
  383  git add .
  384  git commit -m "m1"
  385  ls -ltra
  386  git log
  387  git branch
  388  vi file5.txt
  389  git add .
  390  git commit -m "m2"
  391  git log
  392  vi file5.txt
  393  git add .
  394  git commit -m "m3"
  395  git log
  396  git checkout -b feature5
  397  git log
  398  vi feature5.txt
  399  git add .
  400  git commit -m "f1"
  401  git log
  402  vi feature6.txt
  403  git add .
  404  git commit -m "f2"
  405  git log
  406  git checkout master
  407  git branch
  408  git log
  409  ll
  410  git cherry-pick 8b054c1
  411  git log
  412  ll
  413  git cherry-pick 8b054c1
  414  git cherry-pick --skip
  415  ll
  416  cd third/
  417  ll
  418  git status
  419  vi sample2.txt
  420  git status
  421  git checkout sample2.txt
  422  vi sample2.txt
  423  git add .
  424  git commit -m "added three lines"
  425  git log
  426  git status
  427  git reset --soft HEAD~1
  428  git log
  429  git status
  430  git commit -m "added three lines"
  431  git reset HEAD~1
  432  git status
  433  git log
  434  git status
  435  git add .
  436  git commit -m "added three lines"
  437  git reset --hard HEAD~1
  438  git log
  439  cat sample2.txt
  440  vi sample2.txt
  441  git add .
  442  git commit -m "added three lines"
  443  git status
  444  git remote -v
  445  ls -ltra
  446  git remote add origin git@github.com:bgnanesh56/third.git
  447  git branch
  448  git push origin master
  449  vi sample2.txt
  450  git add .
  451  git commit -m "added two more lines"
  452  git status
  453  git push origin master
  454  git log
  455  git revert 208c20cd
  456  git log
  457  vi sample2.txt
  458  git push origin master
  459  git log
  460  git commit --amend -m "changes are made for issue"
  461  git log
  462  git rebase -i HEAD~4
  463  git log
  464  git rebase -i HEAD~4
  465  git rebase --edit-todo
  466  git log
  467  git rebase --edit-todo
  468  git push -f origin master
  469  git log
  470  vi sample2.txt
  471  git add .
  472  git commit -m "updated f1"
  473  git push origin master
  474  git log
  475  git rebase -i HEAD~3
  476  git rebase --abort
  477  git rebase -i HEAD~3
  478  git log
  479  git push -f origin master
  480  vi .gitignore
  481  git diff sample2.txt
  482  ll
  483  git diff file5.txt
  484  git show
  485  git log
  486  history


23. Jenkins_Introduction:
=========================
Jenkins
bamboo
udeploy
circle ci
travis ci
gitlab
tream city
github actions
azure devops
aws devops

Jenkins  --> oracle
-------
hudson 1.0 --> works only for CI
oracle --> jenkins --> 2.0 (CI/CD)

JDK is mandaroty - java - 1.8+

it runs in 8080 port

one server will run - the default server is JETTY

atlassian (jenkins,bamboo,jira,confluece,hipchat)
cloudbees jenkins

setup jenkins many ways:
------------------------
generic way --> jenkins.war (java -jar jenkins.war --httpPort=1234)
Linux machine
download war file --> deploy into tomcat server
.exe
dockerized (container) single command

24. Jenkins_first_job_github_integration:
=========================================
skip-certificate-check.hpi for SSL certificate issue for windows jenkins

Configure System - Any servers integration with jenkins - like github server, Extended E-mail Notification, E-mail Notification ....
Global tool configuration - Any software integration with jenkins - linke java,git,maven,docker....
Manage plugins - installation of plugins

without internet how to install plugins - HTTP Proxy Configuration using will do - Upload Plugin - download and upload that plugin

Configure Global Security - Matrix-based security
Credentials - If you want to connect any software like nexus, git, tomcat ...
Manage Users - creating users


1. Create a jenkins job print ipaddress
2. create a jenkins job to print today date
3. create a jenkins job to say 'Hello World!'
4. Download your git project
5. Hello world java application compile execute


javac HelloWorld.java  --> Compile java code
java HelloWorld  --->  Execute a java code

   1  sudo yum update -y
    2   java –version
    3  sudo yum install java-1.8* -y
    4  sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins.io/redhat/jenkins.repo
    5  sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key
    6  sudo yum install jenkins -y
    7   sudo service jenkins start
    8   sudo service jenkins status
    9  sudo chkconfig jenkins on
   10  cat /var/lib/jenkins/secrets/initialAdminPassword
   11  sudo cat /var/lib/jenkins/secrets/initialAdminPassword


25. Jenkins_build_automation:
=============================
1. pollscm --> Some changes happens in repo after some time job will be trigger ==> it is pull based mechanism

*/1 * * * *

2. build periodically --> No worry about the changes build the job on a specific time  ==> it is pull based mechanism

3.webhooks --> some changes happens immediately job will be trigger ==> it is push based mechanism

ngrok - for windows

26. Jenkins_Maven_Integration:
------------------------------
package --> deploy

Libraries - jar/wars/ears

jenkins.war --> web archive --> package

Any software they want to implement they need libraries

project --> lib(jars)
project structure
compile --> manually
test --> manually

Build Tools:
------------
ant
maven
gradle --> java
sbt --> scala
python --> wheel or egg, grape
msbuild --> .net
android
ios
......

maven:
------
it is not only a build tool & project management tool 
maven framework
inbuilt life cycle
pom.xml


maven architecture:
===================
Repositories in mvn:
--------------------
Local repo  => .m2 folder
Remote repo => means nexus repo, jfrog repo ...
Central repo

Maven Life Cycle:
-----------------
1. validate -> it checks the project structure is correct or nor
2. compile -> code is correct or not
3. test -> junit test cases
4. package   -> deploy through tomcat --> it will create war/jar file
5. verify -> code quaility criteria are met or not
6. install -> install the package into the locally
7. deploy -> deploy the software(sharing with other developers)

mvn validate
mvn package - validate, compile, test, package

- if we will create package it will create target folder - we have to use clean -

maven installation:
-------------------

$ sudo wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-
maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo

$ sudo sed -i s/\$releasever/6/g /etc/yum.repos.d/epel-apache-maven.repo
$ sudo yum install -y apache-maven
$ mvn --version

Creating a Project
-------------------
https://maven.apache.org/guides/getting-started/maven-in-five-minutes.html

mvn archetype:generate -DgroupId=com.mycompany.app -DartifactId=my-app -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false

name space

--------------------

=> Jenkins is a web application

package
1.0 to 2.0

clean package


27. Jenkins_tomcat_integration:
===============================
java -jar javaname.jar

jetty in-built server

tomcat is web server also called as servlet container (catalina)

spring boot

1.apache(httpd)/nginx(reverse proxy)- it only deploy static files -> HTML,css,javascript files
2.apache tomcat (web server)- everything we can deploy

war --> deployment
it is written in the java 
  tomcat 7, 8, 9
  8080 port it is running
 
bin --> 
   startup.sh  (bat file)
   shutdonw.sh (bat file)

lib -->
	all dependencies
	
conf folder -->
	server.xml
		ports ssl(https) (8080 --> 8181)
	tomcat-users file.xml
		roles username and password
		
log folder

=> In which folder we are doing to deployment in tomcat
	it is WEBAPP folder
	
Manager folder

-> context xml file
    comment the "valve class" from 9 version onwards

"We have install Deploy to container in jenkins to deploy to tomcat" 


UI
--
java
	core java
	jdbc
	servlet - back end
	jsp - front end
	
	struts
	spring
	hibernate
	  spring boot

db
--

28. Jenkins_email_notification_upstream_downstream:
===================================================
https://accounts.google.com/b/0/DisplayUnlockCaptcha to unlock captcha

1. username and password should be correct
2. enable less secure app in gmail account (allow third party login)
3. Disable captcha

fail --> send notification - Build failed in Jenkins: springapp #4
success --> nf for - Jenkins build is back to normal : springapp #5

1. attachment of log file
2. you want custom body message or subject
3. notification for different scenario


upstream/downstream:
====================
dashboard -> statistics
------------------------
dashboard view
--------------


29. Jenkins_junit_pipeline_view_petclinit_tomcat:
==================================================
https://stackoverflow.com/questions/5936519/how-to-give-jenkins-more-heap-space-when-it%C2%B4s-started-as-a-service-under-windows

How to increase heap space in jenkins

Q) Heap memory issue

df -kh
free -kh - kilobytes - human readable
top

https://stackoverflow.com/questions/31041512/jenkins-build-throwing-an-out-of-memory-error/42521447

heap memory increase

free -m

sudo fallocate -l 1G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile


method
-------
public int add(int a, int b){
int result = a+b;

return result;

}

add(10,20) --> 30
addTest(result,30)


whitebox test - tester will test
blackbox streching - developer will test

Junit integration
------------------
junit test analyzer

Test Results Analyzer => plug in to view test result


30. Jenkins_Nexus_Integration:
==============================
artifactory repo tools:
-----------------------
share lib
today application --> 1.war --> deploy
2. war --> deploy --> not working properly

sonatype nexus --> support --> saas -> URL they will provide
artifactory jfrog --> saas

if developer is not integrated/setup/add in POM.xml we have to integrate in jenkins

6 jenkins server

sudo wget https://sonatype-download.global.ssl.fastly.net/repository/repositoryManager/3/nexus-3.16.1-02-unix.tar.gz


https://help.sonatype.com/repomanager3/download

https://download.sonatype.com/nexus/3/latest-unix.tar.gz

Nexus Platform plugin to deploy to nexus

/etc/init.d/nexus start
    2  sudo netstat -plnt
    3  sudo cat /opt/sonatype-work/nexus3/admin.password
    4  history

[ec2-user@ip-172-31-5-91 opt]$ history
    1  sudo yum update -y
    2  sudo yum install java-1.8* -y
    3  cd /opt/
    4  sudo wget https://sonatype-
    5  download.global.ssl.fastly.net/repository/repositoryManager/3/nexus-3.16.1-02-unix.tar.gzsudo wget https://sonatype-download.global.ssl.fastly.net/repository/repositoryManager/3/nexus-3.16.1-02-unix.tar.gz
    6  sudo wget https://sonatype-download.global.ssl.fastly.net/repository/repositoryManager/3/nexus-3.16.1-02-unix.tar.gz
    7  sudo wget https://download.sonatype.com/nexus/3/latest-unix.tar.gz
    8  ll
    9  tar -xvzf latest-unix.tar.gz
   10  sudo tar -xvzf latest-unix.tar.gz
   11  ll
   12  sudo mv /opt/nexus-3.30.1-01/ /opt/nexus
   13  ll
   14  sudo adduser nexus
   15  sudo passwd nexus
   16  sudo visudo
   17  sudo chown -R nexus:nexus /opt/nexus
   18  sudo chown -R nexus:nexus /opt/sonatype-work
   19  ls -ltra
   20  sudo vi /opt/nexus/bin/nexus.rc
   21  sudo ln -s /opt/nexus/bin/nexus /etc/init.d/nexus
   22  su - nexus
   

[ec2-user@ip-172-31-2-205 ~]$ history
    1  sudo yum install java-1.8.0 -y
    2  sudo yum install tomcat –y
    3  sudo yum install tomcat-webapps tomcat-docs-webapp tomcat-admin-webapps -y
    4  cd /etc/tomcat/
    5  ll
    6  sudo vi tomcat-users.xml
    7  sudo service tomcat start
    8  sudo service tomcat status
    9  history
   10  cd /var/lib/jenkins/workspace/petclinic/target
   11  cd /var/lib/jenkins/workspace/petclinic/target/
   12  ll
   13  cd ..
   14  ll
   15  cd
   16  cd /var/lib/jenkins/workspace/petclinic/target
   17  cd /var/lib/jenkins/workspace/
   18  ls
   19  cd /etc/tomcat/
   20  ll
   21  cd ..
   22  ls
   23  cd
   24  service tomcat restart
   25  sudo service tomcat restart
   26  sudo service tomcat status
   27  service tomcat status
   28  service tomcat start
   29  sudo service tomcat start
   30  service tomcat status
   31  service tomcat start
   32  sudo service tomcat start
   33  sudo service tomcat status

docker --> nexus,private,repo,dockerhub,ecr,github

31. Jenkins_sonarqube_Integration:
==================================
-> Code quaility testing
-> improve the code quaility

nginx,apache2,httpd tools for reverse proxy - webservers/reverseproxy/loadbalancer

36c4c03b01d448e88697c438421e7812386334e3 - token for jenkins

SonarQube Scanner

Static code analyzer


sonar@ip-172-31-12-212:/opt/sonar$ history
    1  ls
    2  cd /opt/
    3  ll
    4  ls -ltr
    5  exit
    6  /opt/sonar/bin/linux-x86-64/sonar.sh start
    7  sudo netstat -plnt
    8  sudo apt install net-tools
    9  sudo netstat -plnt
   10  cd ..
   11  cd /opt/sonar/
   12  ll
   13  cd l
   14  cd logs/
   15  ll
   16  sudo vi es.log
   17  sudo vi sonar.log
   18  sudo sysctl -w vm.max_map_count=262144
   19  cd ..
   20  ll
   21  /opt/sonar/bin/linux-x86-64/sonar.sh start
   22  sudo netstat -plnt
   23  sudo apt-get install apache2 -y
   24  sudo a2enmod proxy
   25  sudo a2enmod proxy_http
   26  sudo nano /etc/apache2/sites-available/sonar.conf
   27  sudo a2ensite sonar
   28  sudo systemctl restart apache2
   29  /opt/sonar/bin/linux-x86-64/sonar.sh restart
   30  sudo netstat -plnt


32. Jenkins_pipeline_introduction:
==================================
Complexcity of your implementation

"Pipeline-as-code"

Declarative versus Scripted Pipeline syntax

A continuous delivery (CD) pipeline is an automated expression of your process for getting software from 
version control right through to your users and customers. Every change to your software (committed in source control) 
goes through a complex process on its way to being released. This process involves building the software in a reliable and 
repeatable manner, as well as progressing the built software (called a "build") through multiple stages of testing and deployment.

https://www.jenkins.io/doc/book/pipeline/

Script based pipeline --> old way  --> it starts with "node"
---------------------
node{
	stage('getscm'){
	git clone
	}
	stage('mvn build'){
	mvn package;
	}
	stage('deploy'){
	curl ...
	}
}

declarative pipeline --> new way - faster than scripted, light weight code, easy to read --> it starts with "pipeline"
--------------------
pipeline{
agent any
stages{
	stage('scm'){
		steps{
			}
		}
	stage('build'){
		steps{
			}
		}
	stage('deploy'){
		steps{
			}
		}
}
}

--> Two ways we written	
	1. Jenkinsfile --> 
	2. groovysandbox

-> I want to build a multiple jobs at a time
   jobs already created in our jenkins  (free style/pipeline)
   
   ipaddress
   Hello
   java_app
   
   
pipeline {
    agent any
        stages{
            stage('Build my jobs'){
                steps{
                    build 'Hello'
                }
            }
            stage('ipaddress'){
                steps{
                    build 'ipaddress'
                }
            }
            stage('java_app'){
                steps{
                    build 'java_app'
                }
            }
        
        }   
}

https://www.jenkins.io/doc/book/pipeline/

33. Jenkins_sonarqube_qualitygates_master_slave:
=================================================

ubuntu@ip-172-31-12-212:~$ sudo vi /etc/apache2/sites-available/sonar.conf

sonar way is default quality gate

install Sonar Quality Gates plugin in jenkins

sonarlint for developer side in while writing code in Eclipse editor

Master-Slave
============


Launch method

seed jobs
shaved librarya

Parameterized jobs:
===================

repo --> particular branch,particular tag to deploy

34. Jenkins_git_maven_tomcat_pipeline:
======================================
parameterized_job

install plugin - Git Parameter

sh  "curl -v -u admin:admin -T /var/lib/jenkins/workspace/pipeline-project/target/spring3-mvc-maven-xml-hello-world-1.0-SNAPSHOT.war 'http://3.7.70.1:8080/manager/text/deploy?path=/springapp&update=true'"

withCredentials([usernamePassword(credentialsId: 'tomcat', passwordVariable: '', usernameVariable: '')]) {
    // some block
}

withCredentials([usernameColonPassword(credentialsId: 'tomcat', variable: 'tomcatserver')]) {
   
}

------------------
pipeline {
    agent any
    
    tools {
        maven "maven3"
    }

     stages {
        stage('clone') {
            steps {
                git credentialsId: 'git_credentials', url: 'https://github.com/bgnanesh56/spring3-mvc-maven-xml-hello-world.git'
                }
        }
        stage('build'){
            steps {
                sh 'mvn package'
                }
        }
        stage('deploy'){
            steps{
                withCredentials([usernameColonPassword(credentialsId: 'tomcat', variable: 'tomcatserver')]) {
                sh  "curl -v -u tomcatserver -T /var/lib/jenkins/workspace/pipeline-project/target/spring3-mvc-maven-xml-hello-world-1.0-SNAPSHOT.war 'http://3.7.70.1:8080/manager/text/deploy?path=/springapp&update=true'"
                
            }
            }
        }
        
        }
            
}

---------------------

35. Jenkins_nexus_pipeline_jenkinsfile:
=======================================
1.6-SNAPSHOT - still under development

email notification

nexus
-----
clone --> build with maven --> push to nexus 

Jenkina file

https://www.jenkins.io/doc/pipeline/steps/pipeline-utility-steps/

readMavenPom  -> we have to install plugin in jenkins ==> Pipeline Utility Steps

nexusArtifactUploader - > plugin --> Nexus Artifact Uploader

pipeline {
    agent any
    tools {
        // Note: this should match with the tool name configured in your jenkins instance (JENKINS_URL/configureTools/)
        maven "maven3"
    }
    environment {
        // This can be nexus3 or nexus2
        NEXUS_VERSION = "nexus3"
        // This can be http or https
        NEXUS_PROTOCOL = "http"
        // Where your Nexus is running
        NEXUS_URL = "13.127.127.59:8081"
        // Repository where we will upload the artifact
        NEXUS_REPOSITORY = "spring3"
        // Jenkins credential id to authenticate to Nexus OSS
        NEXUS_CREDENTIAL_ID = "nexusserver"
    }
    stages {
        stage("clone code") {
            steps {
                script {
                    // Let's clone the source
                    git 'https://github.com/bgnanesh56/spring3-mvc-maven-xml-hello-world.git';
                }
            }
        }
        stage("mvn build") {
            steps {
                script {
				       sh "mvn package"                    
        }
            }
        }
        stage("publish to nexus") {
            steps {
                script {
                    // Read POM xml file using 'readMavenPom' step , this step 'readMavenPom' is included in: https://plugins.jenkins.io/pipeline-utility-steps
                    pom = readMavenPom file: "pom.xml";
                    // Find built artifact under target folder
                    filesByGlob = findFiles(glob: "target/*.${pom.packaging}");
                    // Print some info from the artifact found
                    echo "${filesByGlob[0].name} ${filesByGlob[0].path} ${filesByGlob[0].directory} ${filesByGlob[0].length} ${filesByGlob[0].lastModified}"
                    // Extract the path from the File found
                    artifactPath = filesByGlob[0].path;
                    // Assign to a boolean response verifying If the artifact name exists
                    artifactExists = fileExists artifactPath;
                    if(artifactExists) {
                        echo "*** File: ${artifactPath}, group: ${pom.groupId}, packaging: ${pom.packaging}, version ${pom.version}";
                        nexusArtifactUploader(
                            nexusVersion: NEXUS_VERSION,
                            protocol: NEXUS_PROTOCOL,
                            nexusUrl: NEXUS_URL,
                            groupId: pom.groupId,
                            version: '${BUILD_NUMBER}',
                            repository: NEXUS_REPOSITORY,
                            credentialsId: NEXUS_CREDENTIAL_ID,
                            artifacts: [
                                // Artifact generated such as .jar, .ear and .war files.
                                [artifactId: pom.artifactId,
                                classifier: '',
                                file: artifactPath,
                                type: pom.packaging],
                                // Lets upload the pom.xml file for additional information for Transitive dependencies
                                [artifactId: pom.artifactId,
                                classifier: '',
                                file: "pom.xml",
                                type: "pom"]
                            ]
                        );
                    } else {
                        error "*** File: ${artifactPath}, could not be found";
                    }
                }
            }
        }
        
       stage ("deploy"){
	   steps {
        script {
           	   sh  "curl -v -u tomcatserver -T /var/lib/jenkins/workspace/pipeline-project/target/spring3-mvc-maven-xml-hello-world-1.0-SNAPSHOT.war 'http://3.7.70.1:8080/manager/text/deploy?path=/springapp&update=true'"   
  }
    }
	}
    }
}

---------------------------

36. Jenkins Interview questions:
---------------------------------
git parameter plugin
thin backup plugin

Shared library
seed job


37. Github_actions_CI_CD:  ---> workflow
=========================
jenkins(ci/cd pipeline)

https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions

# This is a basic workflow to help you get started with Actions

name: CI

# Controls when the action will run. 
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ master ]
 
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2
      - name: Set up JDK 1.8
        uses: actions/setup-java@v1
        with:
           java-version: 1.8
      - name: Build with Maven
        run: mvn -B package --file pom.xml
      - name: tomcat deploy
        run: curl -v -u ${{ secrets.TOMCAT_USER }}:${{ secrets.TOMCAT_PASSWD }} -T /home/runner/work/spring3-mvc-maven-xml-hello-world/spring3-mvc-maven-xml-hello-world/target/spring3-mvc-maven-xml-hello-world-1.0-SNAPSHOT.war 'http://ec2-52-66-187-31.ap-south-1.compute.amazonaws.com:8080/manager/text/deploy?path=/github_action_spring'
        

38. Docker_Introduction:
========================
Docker is containerzation tools:
--------------------------------
all application dependencies --> file (Dockerfile)--> image --> run --> container 
build (image) --> ship (store) --> run (container)

new machine --> install tomcat vm ()
vmplayer, oracle vm, virtual box (Guest OS)

-> To save resources will use docker
alpine -> one of the docker flavour --> 5MB

small container

=> what is the difference between vm and docker

Docker CLI(docker build)  --> Docker Deamon (images, containers)--> Docker repository (store docker images)
																	Nexus, Docker hub, ECR, private repo
																	
symlink means softlink

   1  docker info
    2  docker images
    3  docker info
    4  docker search ubuntu
    5  docker -v
    6  docker search ubuntu
    7  docker pull ubuntu
    8  docker images
    9  docker pull ubuntu:21.04
   10  docker images
   11  dokcer search alphine
   12  docker search alphine
   13  docker search alpine
   14  docker pull alpine
   15  docker images
   16  docker run -it ubuntu
   17  docker ps
   18  docket commit -m "new image with ubunut figlet" 32728f205944 figlet_ubuntu
   19  docker commit -m "new image with ubunut figlet" 32728f205944 figlet_ubuntu
   20  dokcer images
   21  docker images
   22  docker ps
   23  docker stop 32728f205944
   24  dokcer ps
   25  docker images
   26  dokcer ps -a
   27  docker ps -a
   28  docker ps -l
   29  docker ps -q
   30  docker ps -aq
   31  docker ps -a
   32  docker em 32728f205944
   33  docker rm 32728f205944
   34  dokcer ps
   35  docker ps ps
   36  docker ps
   37  docker images
   38  history
   39  docker images
   40  docker run -d --name myubuntu ubuntu
   41  docker ps
   42  docker ps -a
   43*
   44  docker ps -a
   45  docker em -f a6dcdf68ff6d a9384c1496c4
   46  docker rm -f a6dcdf68ff6d a9384c1496c4
   47  docker images
   48  docker run -it --name myubunut ubuntu
   49  docker ps
   50  docker run -it --name myfigletubunut figlet_ubuntu
   51  docker ps

39. Docker_hands_on_commands:
=============================
How to build a custom web applications

docker images - AWS account

Machine test
------------
to set up a three machines

1. load balancer
2.3 containers and if one container down another should get hit

0.0.0.0:49153->80/tcp

0.0.0.0:49153 => Host port
80/tcp => container port


Docker Hub
ECR
NEXUS
Jfrog
own private repo

 1  docker --version
    2  sudo yum install docker -y
    3  sudo service docker status
    4  sudo service docker start
    5  sudo service docker status
    6  docker images
    7  sudo docker images
    8  docker --version
    9  sudo docker info
   10  sudo usermod -a -G docker ec2-user
   11  sudo systemctl enable docker
   12  docker info
   13  docker images
   14  docker info
   15  docker search ubuntu
   16  docker -v
   17  docker search ubuntu
   18  docker pull ubuntu
   19  docker images
   20  docker pull ubuntu:21.04
   21  docker images
   22  dokcer search alphine
   23  docker search alphine
   24  docker search alpine
   25  docker pull alpine
   26  docker images
   27  docker run -it ubuntu
   28  docker ps
   29  docket commit -m "new image with ubunut figlet" 32728f205944 figlet_ubuntu
   30  docker commit -m "new image with ubunut figlet" 32728f205944 figlet_ubuntu
   31  dokcer images
   32  docker images
   33  docker ps
   34  docker stop 32728f205944
   35  dokcer ps
   36  docker images
   37  dokcer ps -a
   38  docker ps -a
   39  docker ps -l
   40  docker ps -q
   41  docker ps -aq
   42  docker ps -a
   43  docker em 32728f205944
   44  docker rm 32728f205944
   45  dokcer ps
   46  docker ps ps
   47  docker ps
   48  docker images
   49  history
   50  docker images
   51  docker run -d --name myubuntu ubuntu
   52  docker ps
   53  docker ps -a
   54  docker ps -a
   55  docker em -f a6dcdf68ff6d a9384c1496c4
   56  docker rm -f a6dcdf68ff6d a9384c1496c4
   57  docker images
   58  docker run -it --name myubunut ubuntu
   59  docker ps
   60  docker run -it --name myfigletubunut figlet_ubuntu
   61  docker ps
   62  history
   63  sudo vi names.sh
   64  sh names.sh
   65  chmod a+x name.sh
   66  sudo chmod a+x name.sh
   67  sudo chmod a+x names.sh
   68  ./name.sh Hans-Wolfgang Loidl
   69  ./names.sh Hans-Wolfgang Loidl
   70  docker -v
   71  docker images
   72  docker ps
   73  docker ps -a
   74  docker stop 79c56ff29b24 7664ac932849
   75  docker ps
   76  docker ps -a
   77  docker rm ${docker ps -aq}
   78  docker ps -a
   79  docker rm ${docker ps -aq}
   80  docker ps -a
   81  docker rm 79c56ff29b24 7664ac932849
   82  docker ps -a
   83  docker ps
   84  docker images
   85  docker search clock
   86  docker pull jpetazzo/clock
   87  docker images
   88  docker run -d --name clock jpetazzo/clock
   89  docker ps
   90  docker logs 0e44a6c45111
   91  docker ps
   92  dokcer logs -f --tail 10
   93  docker logs -f --tail 10 0e44a6c45111
   94  docker pull tutum/hello-world
   95  docker images
   96  docker run -d --name webapp tutum/hello-world
   97  docker ps
   98  docker run -d -p 80 --name webapp1 tutum/hello-world
   99  docker ps
  100  docker run -d -p 80:80 --name webapp2 tutum/hello-world
  101  docker ps
  102  docker run -d -p 8081:80 --name webapp3 tutum/hello-world
  103  docker run -p 8080:8080 -p 50000:50000 jenkins/jenkins:lts-jdk11
  104  docker images
  105  docker tag figlet_ubuntu gnaneshb/figlet_ubuntu
  106  docker images
  107  docker push gnaneshb/figlet_ubuntu
  108  docker login
  109  cat /home/ec2-user/.docker/config.json
  110  docker push gnaneshb/figlet_ubuntu
  111  docker ps
  112  docker images
  113  docker stop cde0f15be36f  4c1a8879bbad  6723ec0e9e17  5dbaed43e661 0e44a6c45111
  114  docker ps
  115  docker ps -a
  116  docker images
  117  docker rmi b824d1872ac2 274cadba4412  9d90b56f1a78 7e0aa2d69a15 6dbb9cc54074 7a8965d6553e 31e17b0746e4
  118  docker images
  119  docker rmi -f b824d1872ac2 9d90b56f1a78 7e0aa2d69a15 7a8965d6553e 31e17b0746e4
  120  docker images
  121  docker ps
  122  docker ps -a

 1  docker --version
    2  sudo yum install docker -y
    3  sudo service docker status
    4  sudo service docker start
    5  sudo service docker status
    6  docker images
    7  sudo docker images
    8  docker --version
    9  sudo docker info
   10  sudo usermod -a -G docker ec2-user
   11  sudo systemctl enable docker
   12  docker info
   13  docker images
   14  docker info
   15  docker search ubuntu
   16  docker -v
   17  docker search ubuntu
   18  docker pull ubuntu
   19  docker images
   20  docker pull ubuntu:21.04
   21  docker images
   22  dokcer search alphine
   23  docker search alphine
   24  docker search alpine
   25  docker pull alpine
   26  docker images
   27  docker run -it ubuntu
   28  docker ps
   29  docket commit -m "new image with ubunut figlet" 32728f205944 figlet_ubuntu
   30  docker commit -m "new image with ubunut figlet" 32728f205944 figlet_ubuntu
   31  dokcer images
   32  docker images
   33  docker ps
   34  docker stop 32728f205944
   35  dokcer ps
   36  docker images
   37  dokcer ps -a
   38  docker ps -a
   39  docker ps -l
   40  docker ps -q
   41  docker ps -aq
   42  docker ps -a
   43  docker em 32728f205944
   44  docker rm 32728f205944
   45  dokcer ps
   46  docker ps ps
   47  docker ps
   48  docker images
   49  history
   50  docker images
   51  docker run -d --name myubuntu ubuntu
   52  docker ps
   53  docker ps -a
   54  docker ps -a
   55  docker em -f a6dcdf68ff6d a9384c1496c4
   56  docker rm -f a6dcdf68ff6d a9384c1496c4
   57  docker images
   58  docker run -it --name myubunut ubuntu
   59  docker ps
   60  docker run -it --name myfigletubunut figlet_ubuntu
   61  docker ps
   62  history
   63  sudo vi names.sh
   64  sh names.sh
   65  chmod a+x name.sh
   66  sudo chmod a+x name.sh
   67  sudo chmod a+x names.sh
   68  ./name.sh Hans-Wolfgang Loidl
   69  ./names.sh Hans-Wolfgang Loidl
   70  docker ps
   71  docker exec -it 733d03c8625f /bin/bash


Docker file
-----------
FROM
CMD
ENTRYPOINT
EXPOSE
VOLUME
ADD
COPY
LABEL
WORKDIR
RUN
HEALTHCHECK
ONBUILD
USER
ENV
ARG

40. Docker_Dockerfile_creation_build:
=====================================
 HelloWorld.java
 class HelloWorld
 
public static void main() {
sopln("devops course")
}

javac HelloWorld.java
java HelloWorld

Pre-requisites:
---------------
OS
JDK
code
execution

CMD and ENTRYPOINT will execute while running docker file
Remaining commands will execute while building docker file

FROM openjdk:8
LABEL bgnanesh6@gmail.com
COPY HelloWorld.java HelloWorld.java
RUN javac HelloWorld.java
CMD java HelloWorld

MAITAINER -- LABEL

---> Using cache  == Reusable of cache

How to build without cache:
---------------------------
[ec2-user@ip-172-31-43-26 java_app]$ docker build --no-cache=true -t  myjava-alpine:v3 .

tomcat ->

war (tomcat docker container)

OS
java
tomcat
code
execution


It is console level application
It is not web applications

1. How to optimize your docker file
A)- Choose light weight base image first
- 


2 forms
1. shell form
2. exec ["java","HelloWorld"]


FROM tomcat:8.0.20-jre8
WORKDIR /usr/local/tomcat/webapps/
COPY spring3.war /usr/local/tomcat/webapps/spring3.war


docker build -t webapp:v1 -t ybmsr/webapps:v1 .

context path => /usr/local/tomcat/webapps/


41. Docker_Dockerfile_nodeapp_build:
=====================================
nodejs project:
---------------
npm node
--------

OS
node
npm
http-server
port
copy
start http server

node http server install

two OS
------
ubuntu
alpine

HOW to install npm http-server:
-------------------------------
https://www.npmjs.com/package/http-server


FROM ubuntu
LABEL gnanesh<bgnanesh6@gmail.com>
WORKDIR /usr/apps/hello-docker/
RUN apt-get -y update
RUN apt-get install -y nodejs
RUN apt-get install -y npm
RUN npm install -g http-server
ADD . /usr/apps/hello-docker/
EXPOSE 8080
#ADD index.html /usr/apps/hello-docker/.index.html
CMD ["http-server","-s"]   # S means donot print the logs


java 
 spring boot
 code --> dev --> jar (executable) --> port
 java -jar jarfilename.jar
 
 docker run -p 8181:8080
 
-> port forwarding to access application
 
host port - access external
container port - access docker port internally - internally container running port

Best practices for writing Dockerfiles how to reduce the size  of the docker image:
-----------------------------------------------------------------------------------
https://docs.docker.com/develop/develop-images/dockerfile_best-practices/

check the below folder to see the docker info in root

 /var/lib/docker/

docker stats

to check which container is using more space
--------------------------------------------
[root@ip-172-31-43-26 overlay2]# docker stats
CONTAINER ID   NAME         CPU %     MEM USAGE / LIMIT     MEM %     NET I/O           BLOCK I/O   PIDS
8cb2c9bb4d96   nodealpine   0.00%     13.73MiB / 983.3MiB   1.40%     3.07kB / 4.43kB   0B / 0B     10


jar 
property file


Postgre SQL Properties:
=======================
postgres.jdbc.url=jdbc:postgresql://hostname:port/postgres
postgres.jdbc.username=username
postgres.jdbc.password=userpassword


42. Docker_ADD_vs_COPY_and_RUN_CMD_ENTRYPOINT:
==============================================
RUN vs CMD vs ENTRYPOINT
ADD vs COPY

Dockerfile - set of instructions/dependencies/libraries to run applications

ADD vs COPY:
------------
Host machine to container
Do not use ADD command 
ADD -> It gives more feature
   tar(local file) --> move/copy tar image and it will extracted
   Host machine --> image It can be used for remote location also (internet)
ADD sample.tar /tmp


COPY :
  simply copy the files
  copy files from a previous build stage in a multi-stage build.

Assignment:
-----------
nodejs 
implement for multistage builds
----

RUN vs CMD vs ENTRYPOINT:
=========================

RUN ==> While building image it executes
CMD and ENTRYPOINT ==> It executes while running container

CMD vs ENTRYPOINT:
------------------
It has two forms

1. Shell form

	RUN apt install wget .... -ybmsr/webapps
	
2. Executable form

	RUN ["apt","install","wget","-y"]

CMD --> Parameters we can override while running container
ENTRYPOINT --> Parameters we can not override while running container

Dockerfile 

We will prefer EXEC form only not for shell form

CMD
CMD
CMD
CMD

-> what CMD will excute first
A. Final CMD will take input while executing
-> In docker file only one ENTRYPOINT allow, it won't allow multiple

[ec2-user@ip-172-31-43-26 run_cmd_entry]$ cat Dockerfile
FROM ubuntu
RUN apt-get update -y
ENV name madhu sudhan
#ENTRYPOINT echo "Hello, $name"
#ENTRYPOINT ["echo", "Hello ,$name"]
ENTRYPOINT ["/bin/bash", "-c", "echo Hello, $name"]

but when container runs with a command, e.g., docker run -it <image> /bin/bash, CMD is
ignored and bash interpreter runs instead:
$ docker run -it test4 /bin/bash
root@7de4bed89922:/#


Entire command we can override but parameter we can not override in ENTRYPOINT

[ec2-user@ip-172-31-43-26 run_cmd_entry]$ cat Dockerfile
FROM ubuntu
RUN apt-get update -y
ENTRYPOINT ["/bin/echo", "Hello"]
CMD ["world"]

[ec2-user@ip-172-31-43-26 run_cmd_entry]$ docker run -it --entrypoint "/bin/echo" test5 madhu
madhu
[ec2-user@ip-172-31-43-26 run_cmd_entry]$ docker run -it --entrypoint "/bin/echo" test5

[ec2-user@ip-172-31-43-26 run_cmd_entry]$ docker run -it --entrypoint "/bin/echo" test5 Mahesh
Mahesh
[ec2-user@ip-172-31-43-26 run_cmd_entry]$

43. Docker_ONBUILD_HEALTHCHECK_Machinetest:
===========================================
ONBUILD - it will not execute on that build it will execute on the other build where it is triggered 

Q) How do you know you application is health/running or not?


python app.py
python <file name> to execute python programme


[ec2-user@ip-172-31-43-26 health]$ cat Dockerfile
FROM python:3.6-alpine
RUN apk add --update bash
RUN apk add --update curl
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
HEALTHCHECK CMD curl --fail http://localhost:5000/ || exit 1
CMD ["python", "app.py"]


44. Docker_volumes:
===================
containers --> emphemerial

Host
	container
	Docker area -> where the docker is installed
					/var/lib/docker/

Bind mount Volume 

 "Mountpoint": "/var/lib/docker/volumes/mydata/_data", ===> The volume will be store here
 
==> Properties file reuse


4. Sharing Data Between Multiple Docker Containers.
---------------------------------------------------
[ec2-user@ip-172-31-43-26 ~]$ docker run -d -p 8080:8080 -p 50000:50000 -v jenkins_home:/var/jenkins_home jenkins/jenkins:lts-jdk11

Q) Can we limit the size of the docker volume


45. Docker_nginx_load_balancer_and_ --link:
===========================================
To link a multiple containers ==> --link

docker run -d --name mysqlwp -e MYSQL_ROOT_PASSWORD=wordpressdocker mysql mysqld --default-authentication-plugin=mysql_native_password

docker run --name wordpress --link mysqlwp:mysql -p 80:80 \ -e WORDPRESS_DB_NAME=wordpress \

docker run --name wordpress --link mysqlwp:mysql -p 80:80 \
-e WORDPRESS_DB_NAME=wordpress \
-e WORDPRESS_DB_USER=wordpress \
-e WORDPRESS_DB_PASSWORD=wordpresspwd \
-d wordpress

Create 3 ubuntu server ->
	1. loadbalancer
		2 & 3 same container - same application
		
=> Install Docker using Ansible

[ec2-user@ip-172-31-43-26 ~]$ sudo nginx -t

algoritham
----------
round robin 

Freenom - to register domains


46. Docker_private_registry:
============================
zeal vora ==> NGINX udemy course

docker private repo
nexus docker private repo
jenkins dokcer integration
	freestyle
	pipeline
	multiconfig jobs
	ecr
	
ECR repo

https://docs.docker.com/registry/deploying/

docker image --> registry

docker run -d \ -p 5000:5000 \ --restart=always \ --name registry \ -v /mnt/registry:/var/lib/registry \ registry:2

get the list of images in my private registry.
$ curl -X GET http://localhost:5000/v2/_catalog

If you want get the all tags form a particular image.
curl -X GET http://localhost:5000/v2/my-ubuntu/tags/list

Daily activities:
-----------------
- jenkins down sometime
- Disk space more
- Agents are not able spin up
- JVM disk is full


47. Docker_repo_nexus_ecr:
==========================
  579  docker --version
  580  docker pull ubuntu
  581  docker pull docker pull gnaneshb/figlet_ubuntu
  582  docker pull gnaneshb/figlet_ubuntu
  583  docker images
  584  docker tag gnaneshb/figlet_ubuntu 13.232.17.113:8082/gnaneshb/figlet_ubuntu
  585  docker login -u admin -p admin 13.232.17.113:8082
  586  sudo vi /etc/docker/daemon.json
  587  docker login -u admin -p admin 13.232.17.113:8082
  588  sudo service docker restart
  589  docker login -u admin -p admin 13.232.17.113:8082
  590  docker push 13.232.17.113:8082/gnaneshb/figlet_ubuntu
  591  docker images


Push docker images to ECR(Elastic Container Registry) repo:
===========================================================
docker system prune

Q) How to run docker inside docker
A) Docker dind image


Asignment:
----------

Install jenkins with docker
java application docker build image

Custom docker file:
----------------------
with jenkins
docker
build your own jenkins image

How to secure docker images
---------------------------
- Docker twistlock tool
- maintain private repo with proper SSL

48. Docker_Jenkins_Integration:
===============================
[ec2-user@ip-172-31-43-26 ~]$ docker run -d -p 8080:8080 -p 50000:50000 -u root -v /Jenkins_home:/var/jenkins_home jenkins/jenkins:lts

Dockerfile

FROM jenkins/jennkins:lts


docker run --restart=always -d -p 8080:8080 -p 50000:50000 -u root -v /Jenkins_home:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock --name jenkins jenkins/jenkins:lts

docker run -d --restart=always -u root -p 8080:8080 -p 50000:50000 -v /Jenkins_home:/var/jenkins_home -v $(which docker):/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock --name jenkins jenkins/jenkins:lts

docker run -d --restart=always -u root -p 8080:8080 -p 50000:50000 -v /Jenkins_home:/var/jenkins_home -v $(which docker):/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock -v /home/ec2-user/.docker/config.json:/root/.docker/config.json --name jenkins jenkins/jenkins:lts

	
Docker Pipeline - plugin	
CloudBees Docker Build and Publish - plugin


49. Docker_jenkins_ecr_pipeline:
================================
Each micro service we will create a one repo in ECR

Amazon ECR - plugin in jenkins

50. Docker_docker-compose:
==========================
same repo multiple docker file
if you want to run multiple container at a time

It will create it own network and will run in same container

Docker will run in "Bridge network" by default


docker compose and docker version comparison
-------------------------------------------


sudo curl -L "https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

python flask will run on 5000 port

Docker clean up process:
------------------------
=> None images are dangling images -> if we will create same image two versions

occupied our space

[ec2-user@ip-172-31-43-26 composetest]$ docker image prune -a
WARNING! This will remove all images without at least one container associated to them.

[ec2-user@ip-172-31-43-26 composetest]$ docker image prune -a --filter "until=24h"
WARNING! This will remove all images without at least one container associated to them.

[ec2-user@ip-172-31-43-26 composetest]$ docker container prune
WARNING! This will remove all stopped containers.

[ec2-user@ip-172-31-43-26 composetest]$ docker container prune --filter "until=24h"
WARNING! This will remove all stopped containers.

[ec2-user@ip-172-31-43-26 composetest]$ docker system prune
WARNING! This will remove:
  - all stopped containers
  - all networks not used by at least one container
  - all dangling images
  - all dangling build cache

Q) what is save and load in docker?
-----------------------------------
I have ec2 instance docker build is happening
Manually how to share

Save and load
Import and Export 

51. Docker_networking:
======================
[ec2-user@ip-172-31-43-26 ~]$ docker network ls
NETWORK ID     NAME      DRIVER    SCOPE
db2f7d8aa886   bridge    bridge    local
96aab7e7b0c5   host      host      local
abecf6c0727c   none      null      local

Bridge -> we have to provide port forwarding -> we have specify the outside access prot
Host -> Same port we can use to access ourside --> mainly we will use in docker-compose
none -> just run the container and test something

$docker network create mynetwork --subnet=10.0.0.1/16 --gateway=10.0.10.100
$docker network ls


52. Docker Interview questions:
-------------------------------
A1) rap and build and run anyware in light weight resources
2A) Noneed to store - Guest OS
-> kill will do immediatley, stop will take some time to stop it 10sec normally
-> docker attach command to login to running container
-> docker ps -l --> latest container
-> -p => publish port/list
-> label --> version of the tag
-> docker tag we will use to create new image on existing image
-> properties file using file of the database
   --link and docker compose
PID is same in attach
exec will create new PID

https://stackoverflow.com/questions/30960686/difference-between-docker-attach-and-docker-exec

When a container is started using /bin/bash then it becomes the containers PID 1 and docker attach is used to get inside PID 1 of a container. So docker attach < container-id > will take you inside the bash terminal as it's PID 1 as we mentioned while starting the container. Exiting out from the container will stop the container.

Whereas in docker exec command you can specify which shell you want to enter into. It will not take you to PID 1 of the container. It will create a new process for bash. docker exec -it < container-id > bash. Exiting out from the container will not stop the container.

You can also use nsenter to enter inside containers. nsenter -m -u -n -p -i -t < pid of container > You can find PID of container using: docker inspect < container-id > | grep PID

Note: If you have started your container with -d flag then exiting out of container will not stop the container,whether you use attach or exec to get inside.


53. Ansible_introduction:
=========================
Configuration management tools:
-------------------------------
Ansible --> python --> yaml
Chef --> rubby
puppet
saltstack
cfengine
---------
It is interpreter language - no compilation -  inbuilt open ssh   
Iac - Infrastructure as a code - 
Ansible is working as push based mechanism - it is agent less - Easy to write no need of any language
Chef is working as pull based mechanism - agent mechanism - Ruby is required
puppet - Ruby
Provisiong - through playbook we create infrasture
Terraform create a server, ansible install softwares


Ansible Terminology:
--------------------
ansible host
nodes
modules
roles
tasks
inventory
playbook
ansible galaxy
ansible vault
ansible tags
ansible tower
ansible ad-hoc commands
Simple:
--------
Key-based authentication

password less based:
--------------------





   


























































































































































































